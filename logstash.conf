# Logstash configuration for AFMS log processing

input {
  # File input for application logs
  file {
    path => "/usr/share/logstash/logs/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
    tags => ["afms-app"]
  }

  # File input for access logs
  file {
    path => "/usr/share/logstash/logs/access.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    tags => ["nginx-access"]
  }

  # File input for error logs
  file {
    path => "/usr/share/logstash/logs/error.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    tags => ["nginx-error"]
  }

  # Beats input for additional log sources
  beats {
    port => 5044
  }

  # Syslog input
  syslog {
    port => 514
    tags => ["syslog"]
  }
}

filter {
  # Process AFMS application logs
  if "afms-app" in [tags] {
    # Parse JSON logs
    json {
      source => "message"
    }

    # Add timestamp
    date {
      match => [ "timestamp", "ISO8601" ]
    }

    # Extract user information
    if [context][userId] {
      mutate {
        add_field => { "user_id" => "%{[context][userId]}" }
      }
    }

    # Extract request information
    if [context][requestId] {
      mutate {
        add_field => { "request_id" => "%{[context][requestId]}" }
      }
    }

    # Extract trace information
    if [context][traceId] {
      mutate {
        add_field => { "trace_id" => "%{[context][traceId]}" }
      }
    }

    # Categorize log levels
    if [level] == "error" {
      mutate {
        add_tag => [ "error" ]
        add_field => { "severity" => "high" }
      }
    } else if [level] == "warn" {
      mutate {
        add_tag => [ "warning" ]
        add_field => { "severity" => "medium" }
      }
    } else {
      mutate {
        add_field => { "severity" => "low" }
      }
    }

    # Extract business events
    if [eventType] {
      mutate {
        add_field => { "business_event" => "%{[eventType]}" }
        add_tag => [ "business-event" ]
      }
    }

    # Extract performance metrics
    if [context][duration] {
      mutate {
        add_field => { "duration_ms" => "%{[context][duration]}" }
        add_tag => [ "performance" ]
      }
    }

    # Extract security events
    if [eventType] =~ /^(login|logout|auth|security)/ {
      mutate {
        add_tag => [ "security-event" ]
      }
    }

    # Extract attendance events
    if [eventType] =~ /^attendance/ {
      mutate {
        add_tag => [ "attendance-event" ]
      }
    }
  }

  # Process Nginx access logs
  if "nginx-access" in [tags] {
    grok {
      match => { 
        "message" => "%{COMBINEDAPACHELOG} rt=%{NUMBER:request_time:float} uct=\"%{DATA:upstream_connect_time}\" uht=\"%{DATA:upstream_header_time}\" urt=\"%{DATA:upstream_response_time}\""
      }
    }

    # Parse timestamp
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }

    # Convert response code to number
    mutate {
      convert => { "response" => "integer" }
      convert => { "bytes" => "integer" }
    }

    # Categorize response codes
    if [response] >= 500 {
      mutate {
        add_tag => [ "server-error" ]
        add_field => { "severity" => "high" }
      }
    } else if [response] >= 400 {
      mutate {
        add_tag => [ "client-error" ]
        add_field => { "severity" => "medium" }
      }
    } else if [response] >= 300 {
      mutate {
        add_tag => [ "redirect" ]
        add_field => { "severity" => "low" }
      }
    } else {
      mutate {
        add_tag => [ "success" ]
        add_field => { "severity" => "low" }
      }
    }

    # Extract API endpoints
    if [request] =~ /\/api\// {
      mutate {
        add_tag => [ "api-request" ]
      }
    }

    # Detect slow requests
    if [request_time] and [request_time] > 2.0 {
      mutate {
        add_tag => [ "slow-request" ]
      }
    }
  }

  # Process Nginx error logs
  if "nginx-error" in [tags] {
    grok {
      match => {
        "message" => "(?<timestamp>%{YEAR}[./-]%{MONTHNUM}[./-]%{MONTHDAY}[- ]%{TIME}) \[%{LOGLEVEL:severity}\] %{POSINT:pid}#%{NUMBER:tid}: (\*%{NUMBER:connection_id} )?%{GREEDYDATA:error_message}"
      }
    }

    # Parse timestamp
    date {
      match => [ "timestamp", "yyyy/MM/dd HH:mm:ss" ]
    }

    mutate {
      add_tag => [ "nginx-error" ]
    }
  }

  # Common processing for all logs
  # Add hostname
  mutate {
    add_field => { "hostname" => "%{host}" }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "@version" ]
  }

  # GeoIP for client IPs (if available)
  if [clientip] {
    geoip {
      source => "clientip"
      target => "geoip"
    }
  }

  # User agent parsing
  if [agent] {
    useragent {
      source => "agent"
      target => "user_agent"
    }
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "afms-logs-%{+YYYY.MM.dd}"
    template_name => "afms-logs"
    template_pattern => "afms-logs-*"
    template => {
      "index_patterns" => ["afms-logs-*"]
      "settings" => {
        "number_of_shards" => 1
        "number_of_replicas" => 0
        "index.refresh_interval" => "5s"
      }
      "mappings" => {
        "properties" => {
          "@timestamp" => { "type" => "date" }
          "level" => { "type" => "keyword" }
          "message" => { "type" => "text" }
          "severity" => { "type" => "keyword" }
          "user_id" => { "type" => "keyword" }
          "request_id" => { "type" => "keyword" }
          "trace_id" => { "type" => "keyword" }
          "business_event" => { "type" => "keyword" }
          "duration_ms" => { "type" => "float" }
          "response" => { "type" => "integer" }
          "request_time" => { "type" => "float" }
          "clientip" => { "type" => "ip" }
          "geoip" => {
            "properties" => {
              "location" => { "type" => "geo_point" }
              "country_name" => { "type" => "keyword" }
              "city_name" => { "type" => "keyword" }
            }
          }
        }
      }
    }
  }

  # Output errors to separate index
  if "error" in [tags] or [severity] == "high" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "afms-errors-%{+YYYY.MM.dd}"
    }
  }

  # Output business events to separate index
  if "business-event" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "afms-business-events-%{+YYYY.MM.dd}"
    }
  }

  # Output security events to separate index
  if "security-event" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "afms-security-%{+YYYY.MM.dd}"
    }
  }

  # Debug output (comment out in production)
  # stdout {
  #   codec => rubydebug
  # }
}